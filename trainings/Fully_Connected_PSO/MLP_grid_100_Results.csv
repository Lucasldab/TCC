Name,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
AdamW,64,30,0.01,53,0.09200069308280945
Adam,44,32,0.01,128,0.08298443257808685
RMSprop,51,23,0.01,128,0.08949600905179977
AdamW,43,32,0.01,128,0.08614213764667511
AdamW,61,20,0.01,107,0.08246152102947235
Adam,53,19,0.01,93,0.08599461615085602
RMSprop,64,32,0.01,120,0.08346572518348694
AdamW,53,20,0.01,128,0.07939424365758896
Adam,64,25,0.01,106,0.07492963969707489
Adam,53,17,0.01,99,0.08997549116611481
RMSprop,64,29,0.01,102,0.08829103410243988
AdamW,43,32,0.01,128,0.08902440220117569
AdamW,42,32,0.01,95,0.09495050460100174
Adam,50,24,0.01,54,0.09775266796350479
Adam,53,28,0.01,77,0.08380402624607086
Adadelta,60,29,0.01,114,1.2220886945724487
RMSprop,56,32,0.01,128,0.08427136391401291
Adam,34,23,0.01,95,0.10970468819141388
RMSprop,47,28,0.01,124,0.09337756037712097
SGD,52,32,0.01,102,0.42469322681427
