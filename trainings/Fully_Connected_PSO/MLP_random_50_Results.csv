Name,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
Ftrl,37,23,0.01,52,2.301189422607422
Nadam,45,32,0.01,62,0.09595382958650589
Nadam,64,22,0.01,123,0.06944563239812851
Ftrl,59,30,0.01,100,2.3011913299560547
Ftrl,41,32,0.01,97,2.301189422607422
Adamax,49,21,0.01,120,0.09045232832431793
Nadam,64,28,0.01,90,0.07991234213113785
Nadam,64,32,0.01,128,0.06764417886734009
Ftrl,64,24,0.01,77,2.3011903762817383
Adamax,61,32,0.01,124,0.07164756953716278
Adam,48,32,0.01,128,0.08467881381511688
Nadam,64,24,0.01,58,0.08687648177146912
Adadelta,44,21,0.01,118,1.5650300979614258
Nadam,64,27,0.01,79,0.08089178055524826
Adagrad,49,32,0.01,125,0.3191148340702057
Ftrl,45,28,0.01,115,2.30119252204895
Ftrl,62,32,0.01,64,2.3011868000030518
Ftrl,59,28,0.01,82,2.3011910915374756
Adadelta,39,26,0.01,65,1.1902861595153809
Adadelta,52,32,0.01,107,1.3626817464828491
