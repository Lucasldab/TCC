{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.7 MB 325.1 kB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.1/1.7 MB 655.4 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.7 MB 952.6 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.4/1.7 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.7 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.9/1.7 MB 2.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.2/1.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  np.object,\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\PesquisaArtigo\\TCC_Hyperparameters Optimization\\MLP_CNN.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/MLP_CNN.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/MLP_CNN.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/MLP_CNN.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/MLP_CNN.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/MLP_CNN.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     44\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\__init__.py:45\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[0;32m     42\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \n\u001b[0;32m     44\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m keras\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     24\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m INFINITE \u001b[39mas\u001b[39;00m INFINITE_CARDINALITY\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     95\u001b[0m \u001b[39m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m \u001b[39mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbatching\u001b[39;00m \u001b[39mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_service_ops\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserver_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m DispatchServer\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserver_lib\u001b[39;00m \u001b[39mimport\u001b[39;00m WorkerServer\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m compression_ops\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute_options\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoShardPolicy\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute_options\u001b[39;00m \u001b[39mimport\u001b[39;00m ExternalStatePolicy\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\compression_ops.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m division\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m gen_experimental_dataset_ops \u001b[39mas\u001b[39;00m ged_ops\n\u001b[0;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompress\u001b[39m(element):\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwrapt\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m nest\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m composite_tensor\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py:41\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msix\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_six\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m---> 41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m sparse_tensor \u001b[39mas\u001b[39;00m _sparse_tensor\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m collections_abc \u001b[39mas\u001b[39;00m _collections_abc\n\u001b[0;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sorted\u001b[39m(dict_):\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\framework\\sparse_tensor.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m tf2\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m composite_tensor\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m constant_op\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m execute\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_callbacks\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tfe\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m dtypes\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m ops\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:513\u001b[0m\n\u001b[0;32m    482\u001b[0m     _NP_TO_TF[pdt] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\n\u001b[0;32m    483\u001b[0m         _NP_TO_TF[dt] \u001b[39mfor\u001b[39;00m dt \u001b[39min\u001b[39;00m _NP_TO_TF \u001b[39mif\u001b[39;00m dt \u001b[39m==\u001b[39m pdt()\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m    486\u001b[0m TF_VALUE_DTYPES \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(_NP_TO_TF\u001b[39m.\u001b[39mvalues())\n\u001b[0;32m    489\u001b[0m _TF_TO_NP \u001b[39m=\u001b[39m {\n\u001b[0;32m    490\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_HALF:\n\u001b[0;32m    491\u001b[0m         np\u001b[39m.\u001b[39mfloat16,\n\u001b[0;32m    492\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_FLOAT:\n\u001b[0;32m    493\u001b[0m         np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m    494\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_DOUBLE:\n\u001b[0;32m    495\u001b[0m         np\u001b[39m.\u001b[39mfloat64,\n\u001b[0;32m    496\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT32:\n\u001b[0;32m    497\u001b[0m         np\u001b[39m.\u001b[39mint32,\n\u001b[0;32m    498\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT8:\n\u001b[0;32m    499\u001b[0m         np\u001b[39m.\u001b[39muint8,\n\u001b[0;32m    500\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT16:\n\u001b[0;32m    501\u001b[0m         np\u001b[39m.\u001b[39muint16,\n\u001b[0;32m    502\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT32:\n\u001b[0;32m    503\u001b[0m         np\u001b[39m.\u001b[39muint32,\n\u001b[0;32m    504\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT64:\n\u001b[0;32m    505\u001b[0m         np\u001b[39m.\u001b[39muint64,\n\u001b[0;32m    506\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT16:\n\u001b[0;32m    507\u001b[0m         np\u001b[39m.\u001b[39mint16,\n\u001b[0;32m    508\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT8:\n\u001b[0;32m    509\u001b[0m         np\u001b[39m.\u001b[39mint8,\n\u001b[0;32m    510\u001b[0m     \u001b[39m# NOTE(touts): For strings we use np.object as it supports variable length\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[39m# strings.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_STRING:\n\u001b[1;32m--> 513\u001b[0m         np\u001b[39m.\u001b[39;49mobject,\n\u001b[0;32m    514\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX64:\n\u001b[0;32m    515\u001b[0m         np\u001b[39m.\u001b[39mcomplex64,\n\u001b[0;32m    516\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX128:\n\u001b[0;32m    517\u001b[0m         np\u001b[39m.\u001b[39mcomplex128,\n\u001b[0;32m    518\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT64:\n\u001b[0;32m    519\u001b[0m         np\u001b[39m.\u001b[39mint64,\n\u001b[0;32m    520\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BOOL:\n\u001b[0;32m    521\u001b[0m         np\u001b[39m.\u001b[39mbool,\n\u001b[0;32m    522\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT8:\n\u001b[0;32m    523\u001b[0m         _np_qint8,\n\u001b[0;32m    524\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT8:\n\u001b[0;32m    525\u001b[0m         _np_quint8,\n\u001b[0;32m    526\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT16:\n\u001b[0;32m    527\u001b[0m         _np_qint16,\n\u001b[0;32m    528\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT16:\n\u001b[0;32m    529\u001b[0m         _np_quint16,\n\u001b[0;32m    530\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT32:\n\u001b[0;32m    531\u001b[0m         _np_qint32,\n\u001b[0;32m    532\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BFLOAT16:\n\u001b[0;32m    533\u001b[0m         _np_bfloat16,\n\u001b[0;32m    534\u001b[0m \n\u001b[0;32m    535\u001b[0m     \u001b[39m# Ref types\u001b[39;00m\n\u001b[0;32m    536\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_HALF_REF:\n\u001b[0;32m    537\u001b[0m         np\u001b[39m.\u001b[39mfloat16,\n\u001b[0;32m    538\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_FLOAT_REF:\n\u001b[0;32m    539\u001b[0m         np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m    540\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_DOUBLE_REF:\n\u001b[0;32m    541\u001b[0m         np\u001b[39m.\u001b[39mfloat64,\n\u001b[0;32m    542\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT32_REF:\n\u001b[0;32m    543\u001b[0m         np\u001b[39m.\u001b[39mint32,\n\u001b[0;32m    544\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT32_REF:\n\u001b[0;32m    545\u001b[0m         np\u001b[39m.\u001b[39muint32,\n\u001b[0;32m    546\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT8_REF:\n\u001b[0;32m    547\u001b[0m         np\u001b[39m.\u001b[39muint8,\n\u001b[0;32m    548\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT16_REF:\n\u001b[0;32m    549\u001b[0m         np\u001b[39m.\u001b[39muint16,\n\u001b[0;32m    550\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT16_REF:\n\u001b[0;32m    551\u001b[0m         np\u001b[39m.\u001b[39mint16,\n\u001b[0;32m    552\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT8_REF:\n\u001b[0;32m    553\u001b[0m         np\u001b[39m.\u001b[39mint8,\n\u001b[0;32m    554\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_STRING_REF:\n\u001b[0;32m    555\u001b[0m         np\u001b[39m.\u001b[39mobject,\n\u001b[0;32m    556\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX64_REF:\n\u001b[0;32m    557\u001b[0m         np\u001b[39m.\u001b[39mcomplex64,\n\u001b[0;32m    558\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_COMPLEX128_REF:\n\u001b[0;32m    559\u001b[0m         np\u001b[39m.\u001b[39mcomplex128,\n\u001b[0;32m    560\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_INT64_REF:\n\u001b[0;32m    561\u001b[0m         np\u001b[39m.\u001b[39mint64,\n\u001b[0;32m    562\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_UINT64_REF:\n\u001b[0;32m    563\u001b[0m         np\u001b[39m.\u001b[39muint64,\n\u001b[0;32m    564\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BOOL_REF:\n\u001b[0;32m    565\u001b[0m         np\u001b[39m.\u001b[39mbool,\n\u001b[0;32m    566\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT8_REF:\n\u001b[0;32m    567\u001b[0m         _np_qint8,\n\u001b[0;32m    568\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT8_REF:\n\u001b[0;32m    569\u001b[0m         _np_quint8,\n\u001b[0;32m    570\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT16_REF:\n\u001b[0;32m    571\u001b[0m         _np_qint16,\n\u001b[0;32m    572\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QUINT16_REF:\n\u001b[0;32m    573\u001b[0m         _np_quint16,\n\u001b[0;32m    574\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_QINT32_REF:\n\u001b[0;32m    575\u001b[0m         _np_qint32,\n\u001b[0;32m    576\u001b[0m     types_pb2\u001b[39m.\u001b[39mDT_BFLOAT16_REF:\n\u001b[0;32m    577\u001b[0m         _np_bfloat16,\n\u001b[0;32m    578\u001b[0m }\n\u001b[0;32m    580\u001b[0m _QUANTIZED_DTYPES_NO_REF \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m([qint8, quint8, qint16, quint16, qint32])\n\u001b[0;32m    581\u001b[0m _QUANTIZED_DTYPES_REF \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(\n\u001b[0;32m    582\u001b[0m     [qint8_ref, quint8_ref, qint16_ref, quint16_ref, qint32_ref])\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tcc\\lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import losses\n",
    "from optimizer_selector import randomize_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/training_CNN_results.csv'):\n",
    "     with open('data/training_CNN_results.csv', 'w', newline='') as file:\n",
    "          writer = csv.writer(file)\n",
    "          writer.writerow([\"Convoluted_Layers\",\"Convoluted_Filters\",\"Hidden_Layer1\", \"Hidden_Layer2\", \"Learning_Rate\",\"Batch_Size\",\"Loss\"])\n",
    "          file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((60000,28,28,1))\n",
    "x_train = x_train.astype('float32')/255\n",
    "\n",
    "x_test = x_test.reshape((10000,28,28,1))\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_n = random.randint(16, 32)\n",
    "conv_f = random.randint(1, 3)\n",
    "model.add(layers.Conv2D(conv_n,(conv_f), activation='relu', input_shape = (28,28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(conv_n,(conv_f), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "L1 = random.randint(32, 64)\n",
    "model.add(layers.Dense(L1,activation = 'relu'))\n",
    "L2 = random.randint(16, 32)\n",
    "model.add(layers.Dense(L2,activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation= 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, l_rate = randomize_selector(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "bt_size = random.randint(32, 128)\n",
    "epoc=5\n",
    "history = model.fit(x_train, y_train, epochs=epoc, batch_size = bt_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 9, 9, 32)          9248      \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2592)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 32)                82976     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102122 (398.91 KB)\n",
      "Trainable params: 102122 (398.91 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(\"Optmizer:\", name, \"Convoluted Layers:\", conv_n, \"Convoluted Filters:\", conv_f, \"Hidden Layer 1:\", L1, \"Hidden Layer 2:\", L2, \"Learning Rate:\", l_rate, \"Batch Size:\", bt_size, \"Loss:\", history_dict['loss'][epoc-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19296\\623161954.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\Lucas\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "with open('data/training_CNN_results_v2.csv', 'a', newline='') as file:\n",
    "     writer = csv.writer(file)\n",
    "     writer.writerow([name,conv_n, conv_f, L1, L2, l_rate, bt_size, history_dict['loss'][epoc-1]])\n",
    "     file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "#print(\"Hidden Layer 1:\", L1,\"Hidden Layer 2:\", L2,\"Learning Rate:\", l_rate,\"Loss:\", history_dict['loss'][epoc-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/training_results.csv', 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "     \n",
    "    writer.writerow([L1, L2, l_rate,history_dict['loss'][epoc-1]])\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
