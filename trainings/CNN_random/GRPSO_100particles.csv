Name,Convoluted_Layers1,Convoluted_Filters1,Convoluted_Layers2,Convoluted_Filters2,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Best_Value
AdamW,24,3,32,3,64,25,0.01,52,-0.3528473867923216
Adamax,32,3,22,3,43,28,0.01,100,-0.3530395985347002
AdamW,21,1,25,3,56,27,0.01,101,-0.34163285753193084
Adam,32,3,22,3,53,32,0.01,88,-0.3522101812552758
RMSprop,31,3,27,3,64,30,0.01,88,-0.35177159718324374
Adagrad,32,3,32,3,64,18,0.01,86,-0.3451138780836797
Adam,22,3,32,3,64,32,0.01,122,-0.35249569033869343
Adam,32,3,26,3,58,28,0.01,85,-0.3436272488914937
AdamW,27,3,24,3,57,32,0.01,97,-0.35374277296064927
AdamW,21,3,26,3,57,32,0.01,126,-0.35107459629603
Adam,31,3,32,3,42,32,0.01,43,-0.35356687638769047
AdamW,28,3,30,3,42,32,0.01,128,-0.34710703209824934
Adam,32,3,32,3,64,31,0.01,50,-0.33189537532021235
RMSprop,21,3,31,3,57,25,0.01,48,-0.34629618016335423
RMSprop,32,3,28,3,25,32,0.01,89,-0.3458801937032972
Adam,32,3,21,3,63,26,0.01,120,-0.3419545692712217
RMSprop,31,3,24,3,64,29,0.01,128,-0.3486027495032957
AdamW,32,3,22,3,60,32,0.01,59,-0.33287545445084965
RMSprop,32,3,24,3,60,28,0.01,128,-0.3363462422448969
RMSprop,24,3,31,3,64,25,0.01,82,-0.35327442403347287
