Name,Convoluted_Layers1,Convoluted_Filters1,Convoluted_Layers2,Convoluted_Filters2,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
AdamW,24,3,32,3,64,25,0.01,52,0.05637895688414574
Adamax,32,3,22,3,43,28,0.01,100,0.030003182590007782
AdamW,21,1,25,3,56,27,0.01,101,0.05816693603992462
Adam,32,3,22,3,53,32,0.01,88,0.046190593391656876
RMSprop,31,3,27,3,64,30,0.01,88,0.06361998617649078
Adagrad,32,3,32,3,64,18,0.01,86,0.09378710389137268
Adam,22,3,32,3,64,32,0.01,122,0.040438245981931686
Adam,32,3,26,3,58,28,0.01,85,0.04568159580230713
AdamW,27,3,24,3,57,32,0.01,97,0.047491803765296936
AdamW,21,3,26,3,57,32,0.01,126,0.03936534747481346
Adam,31,3,32,3,42,32,0.01,43,0.06121731549501419
AdamW,28,3,30,3,42,32,0.01,128,0.04320695623755455
Adam,32,3,32,3,64,31,0.01,50,0.059440262615680695
RMSprop,21,3,31,3,57,25,0.01,48,0.10014112293720245
RMSprop,32,3,28,3,25,32,0.01,89,0.06579253822565079
Adam,32,3,21,3,63,26,0.01,120,0.038451436907052994
RMSprop,31,3,24,3,64,29,0.01,128,0.05940287932753563
AdamW,32,3,22,3,60,32,0.01,59,0.06234583258628845
RMSprop,32,3,24,3,60,28,0.01,128,0.04963970184326172
RMSprop,24,3,31,3,64,25,0.01,82,0.06302838772535324
