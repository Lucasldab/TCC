Name,Convoluted_Layers1,Convoluted_Filters1,Convoluted_Layers2,Convoluted_Filters2,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
Adam,29,3,32,3,57,25,0.01,101,0.043603770434856415
AdamW,32,3,32,3,61,22,0.01,84,0.04705413803458214
RMSprop,32,3,32,3,42,32,0.01,116,0.04855804517865181
Adagrad,32,3,26,3,64,32,0.01,51,0.06976604461669922
SGD,28,3,24,3,49,32,0.01,64,0.10920889675617218
SGD,32,2,30,3,64,32,0.01,40,0.09922602027654648
Adam,23,3,32,3,61,22,0.01,128,0.044748011976480484
RMSprop,32,3,24,3,59,28,0.01,128,0.050173692405223846
Adam,32,2,29,3,64,25,0.01,128,0.041550878435373306
AdamW,27,3,32,3,47,19,0.01,42,0.061615414917469025
Adadelta,25,3,16,2,53,21,0.01,79,0.6084367632865906
RMSprop,20,3,32,3,50,31,0.01,93,0.0591290146112442
RMSprop,21,3,29,3,62,32,0.01,50,0.09971990436315536
RMSprop,32,3,8,3,45,23,0.01,97,0.07251213490962982
Adam,26,3,32,3,48,32,0.01,72,0.05287531763315201
AdamW,23,3,32,3,64,32,0.01,99,0.04141177982091904
Adam,21,3,21,3,62,31,0.01,104,0.04145176708698273
Adadelta,31,3,23,3,63,32,0.01,84,0.47874462604522705
AdamW,26,3,32,3,37,24,0.01,54,0.05223214998841286
Adam,31,2,30,3,50,21,0.01,128,0.0390133298933506
