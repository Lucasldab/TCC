Name,Convoluted_Layers1,Convoluted_Filters1,Convoluted_Layers2,Convoluted_Filters2,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
Adam,27,3,22,3,64,31,0.01,128,0.0380888395011425
Adam,32,3,22,3,48,20,0.01,78,0.053216468542814255
Adam,25,3,27,3,57,31,0.01,123,0.047445956617593765
AdamW,26,3,24,3,61,32,0.01,78,0.05215495452284813
Adagrad,25,3,29,3,60,28,0.01,80,0.08978024870157242
Adam,32,3,25,3,64,28,0.01,60,0.056771546602249146
AdamW,24,3,32,3,61,29,0.01,128,0.04238693416118622
AdamW,26,3,21,3,58,32,0.01,52,0.058023206889629364
AdamW,29,3,32,3,54,29,0.01,92,0.044618017971515656
AdamW,21,3,26,3,58,28,0.01,128,0.0395752415060997
Adadelta,26,3,30,3,64,32,0.01,125,0.4936348497867584
Adam,32,3,24,3,37,29,0.01,112,0.041193388402462006
Adam,30,3,26,3,58,31,0.01,84,0.046506255865097046
AdamW,24,3,30,3,64,24,0.01,118,0.03844865411520004
AdamW,32,2,30,3,41,32,0.01,108,0.042182426899671555
RMSprop,32,3,32,3,62,27,0.01,89,0.06036045774817467
Adadelta,32,3,29,3,45,25,0.01,114,0.5134285092353821
AdamW,26,3,26,3,55,23,0.01,64,0.050838664174079895
RMSprop,32,3,28,3,56,25,0.01,88,0.07650390267372131
AdamW,22,3,16,3,51,26,0.01,79,0.05508781969547272
