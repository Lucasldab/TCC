{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #& C:/Users/Lucas/anaconda3/envs/tcc/python.exe \"d:/Projetos/PesquisaArtigo/TCC_Hyperparameters Optimization/CNN training.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "import pandas as pd\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetNumber = 1\n",
    "samplingMethod = 'LHS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetLocal = 'trainings/CNN_'+ samplingMethod +'/training_'+ str(datasetNumber) +'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(datasetLocal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'Name': hp.choice('Name', ['SGD', 'RMSprop', 'Adam', 'AdamW', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']),  # Categorical hyperparameter\n",
    "    'Convoluted_Layers1': hp.quniform('Convoluted_Layers1', 16, 32, 1),  # Integer hyperparameter\n",
    "    'Convoluted_Filters1': hp.quniform('Convoluted_Filters1', 1, 3, 1),  # Integer hyperparameter\n",
    "    'Convoluted_Layers2': hp.quniform('Convoluted_Layers2', 16, 32, 1),\n",
    "    'Convoluted_Filters2': hp.quniform('Convoluted_Filters2', 1, 3, 1),\n",
    "    'Hidden_Layer1': hp.quniform('Hidden_Layer1', 32, 64, 1),\n",
    "    'Hidden_Layer2': hp.quniform('Hidden_Layer2', 16, 32, 1),\n",
    "    'Learning_Rate': hp.loguniform('Learning_Rate', 0.0001, 0.01),\n",
    "    'Batch_Size': hp.quniform('Batch_Size', 32, 128, 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    # Extract hyperparameters from the 'params' dictionary\n",
    "    name = params['Name']\n",
    "    conv_layers1 = int(params['Convoluted_Layers1'])\n",
    "    conv_filters1 = int(params['Convoluted_Filters1'])\n",
    "    conv_layers2 = int(params['Convoluted_Layers2'])\n",
    "    conv_filters2 = int(params['Convoluted_Filters2'])\n",
    "    hidden_layer1 = int(params['Hidden_Layer1'])\n",
    "    hidden_layer2 = int(params['Hidden_Layer2'])\n",
    "    learning_rate = float(params['Learning_Rate'])\n",
    "    batch_size = int(params['Batch_Size'])\n",
    "    \n",
    "    \n",
    "    # Perform cross-validation on your dataset\n",
    "    scores = cross_val_score(model, data.drop('target_column', axis=1), data['target_column'], cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Calculate the average accuracy across cross-validation folds\n",
    "    avg_accuracy = scores.mean()\n",
    "    \n",
    "    # We want to minimize 1 - avg_accuracy (maximize accuracy)\n",
    "    return 1 - avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a hypothetical objective function for optimization\n",
    "# Replace this with your actual machine learning model and dataset\n",
    "def objective(params):\n",
    "    \n",
    "\n",
    "    name = params['Name']\n",
    "    conv_layers1 = params['Convoluted_Layers1']\n",
    "    conv_filters1 = params['Convoluted_Filters1']\n",
    "    conv_layers2 = params['Convoluted_Layers2']\n",
    "    conv_filters2 = params['Convoluted_Filters2']\n",
    "    hidden_layer1 = params['Hidden_Layer1']\n",
    "    hidden_layer2 = params['Hidden_Layer2']\n",
    "    learning_rate = params['Learning_Rate']\n",
    "    batch_size = params['Batch_Size']\n",
    "\n",
    "    model = create_and_train_model(params)\n",
    "\n",
    "    # Replace this with your actual model training and evaluation\n",
    "    # Example: Train a deep learning model using these hyperparameters\n",
    "    loss = params['Loss']  # Calculate your loss metric\n",
    "\n",
    "    return {'loss': loss, 'status': hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: 'Loss'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\Projetos\\PesquisaArtigo\\TCC_Hyperparameters Optimization\\TPE.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trials \u001b[39m=\u001b[39m Trials()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Use TPE to search for the best hyperparameters\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best \u001b[39m=\u001b[39m fmin(fn\u001b[39m=\u001b[39;49mobjective,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m             space\u001b[39m=\u001b[39;49mspace,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m             algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m             max_evals\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,  \u001b[39m# Adjust the number of evaluations as needed\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             trials\u001b[39m=\u001b[39;49mtrials)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, best)\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[0;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[0;32m    541\u001b[0m         fn,\n\u001b[0;32m    542\u001b[0m         space,\n\u001b[0;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[1;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[0;32m    672\u001b[0m     fn,\n\u001b[0;32m    673\u001b[0m     space,\n\u001b[0;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[0;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[0;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[0;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[0;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[0;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[0;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[0;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[0;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[0;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[0;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[0;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[0;32m    689\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[0;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[0;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\Lucas\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[0;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "\u001b[1;32md:\\Projetos\\PesquisaArtigo\\TCC_Hyperparameters Optimization\\TPE.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m batch_size \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39m\u001b[39mBatch_Size\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Replace this with your actual model training and evaluation\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Example: Train a deep learning model using these hyperparameters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m params[\u001b[39m'\u001b[39;49m\u001b[39mLoss\u001b[39;49m\u001b[39m'\u001b[39;49m]  \u001b[39m# Calculate your loss metric\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projetos/PesquisaArtigo/TCC_Hyperparameters%20Optimization/TPE.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: loss, \u001b[39m'\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m'\u001b[39m: hyperopt\u001b[39m.\u001b[39mSTATUS_OK}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Loss'"
     ]
    }
   ],
   "source": [
    "# Create a Trials object to keep track of the optimization process\n",
    "trials = Trials()\n",
    "\n",
    "# Use TPE to search for the best hyperparameters\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=100,  # Adjust the number of evaluations as needed\n",
    "            trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective function to optimize\n",
    "def objective(params):\n",
    "\n",
    "    # Calculate cross-validated accuracy\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    mean_accuracy = np.mean(scores)\n",
    "\n",
    "    return {'loss': 1 - mean_accuracy, 'status': STATUS_OK}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
