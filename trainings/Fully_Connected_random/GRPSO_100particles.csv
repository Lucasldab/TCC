Name,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Best_Value
AdamW,58,30,0.01,90,-0.3437873690768952
Ftrl,60,32,0.01,57,-0.3327911327574442
Adamax,51,21,0.01,128,-0.3303563129440306
Adagrad,52,28,0.01,66,-0.3479591586376423
Ftrl,64,32,0.01,89,-0.3341172022753071
Adagrad,64,27,0.01,128,-0.3379119991326438
Nadam,39,25,0.01,118,-0.34106416359438974
Ftrl,63,25,0.01,78,-0.33204884800544787
Adadelta,26,29,0.01,128,-0.33555592089767
Adagrad,44,19,0.01,107,-0.3493014320468818
Adagrad,44,31,0.01,107,-0.32707959204369474
Nadam,53,16,0.01,113,-0.33879528769959266
Adamax,41,32,0.01,118,-0.3494212081085158
Adam,59,20,0.01,128,-0.3505509238866563
SGD,60,24,0.01,76,-0.33426048705072847
Adadelta,60,24,0.01,128,-0.3376376887041842
Nadam,59,20,0.01,108,-0.34803566356723503
AdamW,42,27,0.01,128,-0.3376350514517516
Ftrl,52,32,0.01,128,-0.33932714213658083
AdamW,49,27,0.01,107,-0.3423599448054846
