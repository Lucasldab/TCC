{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_floats_at_end_of_lines(text):\n",
    "    # Define a regular expression pattern to match float numbers at the end of each line\n",
    "    float_pattern = r\"[-+]?\\d*\\.\\d+$|\\d+$\"\n",
    "\n",
    "    # Use re.findall to extract float numbers from the end of each line in the text\n",
    "    float_numbers = [float(match.group()) for line in text.splitlines() if (match := re.search(float_pattern, line.strip())) is not None]\n",
    "\n",
    "    # Convert the extracted float numbers to a NumPy array\n",
    "    float_array = np.array(float_numbers, dtype=float)\n",
    "\n",
    "    return float_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 999 into shape (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m teste \u001b[38;5;241m=\u001b[39m extract_floats_at_end_of_lines(csv_text)\n\u001b[0;32m      7\u001b[0m teste \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(teste)\n\u001b[1;32m----> 9\u001b[0m reshaped_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mteste\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m column_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvoluted_Layers1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvoluted_Filters1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvoluted_Layers2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConvoluted_Filters2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHidden_Layer1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHidden_Layer2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning_Rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch_Size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     14\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(reshaped_matrix, columns\u001b[38;5;241m=\u001b[39mcolumn_names)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 999 into shape (10)"
     ]
    }
   ],
   "source": [
    "csv_file_path= ('trainings/CNN_TPE/training_11.csv')\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    csv_text = file.read()\n",
    "\n",
    "teste = extract_floats_at_end_of_lines(csv_text)\n",
    "\n",
    "teste = np.array(teste)\n",
    "\n",
    "reshaped_matrix = teste.reshape(-1, 10)\n",
    "\n",
    "column_names = ['Name', 'Convoluted_Layers1', 'Convoluted_Filters1', 'Convoluted_Layers2', 'Convoluted_Filters2',\n",
    "                'Hidden_Layer1', 'Hidden_Layer2', 'Learning_Rate', 'Batch_Size', 'Loss']\n",
    "\n",
    "df = pd.DataFrame(reshaped_matrix, columns=column_names)\n",
    "df['Name'] = df['Name'].round().astype(int)\n",
    "df['Convoluted_Layers1'] = df['Convoluted_Layers1'].round().astype(int)\n",
    "df['Convoluted_Filters1'] = df['Convoluted_Filters1'].round().astype(int)\n",
    "df['Convoluted_Layers2'] = df['Convoluted_Layers2'].round().astype(int)\n",
    "df['Convoluted_Filters2'] = df['Convoluted_Filters2'].round().astype(int)\n",
    "df['Hidden_Layer1'] = df['Hidden_Layer1'].round().astype(int)\n",
    "df['Hidden_Layer2'] = df['Hidden_Layer2'].round().astype(int)\n",
    "df['Batch_Size'] = df['Batch_Size'].round().astype(int)\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path= ('trainings/CNN_TPE/training_14.csv')\n",
    "with open(csv_file_path, 'r') as file:\n",
    "    csv_text = file.read()\n",
    "\n",
    "teste = extract_floats_at_end_of_lines(csv_text)\n",
    "\n",
    "teste = np.array(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
