Name,Hidden_Layer1,Hidden_Layer2,Learning_Rate,Batch_Size,Loss
Ftrl,50,32,1.0080868593123227,52,2.3027150630950928
Adadelta,34,19,1.0020338682971819,123,0.12788686156272888
Adagrad,60,30,1.0075156026252101,76,2.302830696105957
SGD,62,17,1.0003754470721058,90,0.2113325297832489
Adagrad,45,28,1.008033146462836,126,2.302489995956421
Adamax,60,30,1.0053423641353452,81,2.2422406673431396
Adamax,43,19,1.0033676318779177,124,1.6738553047180176
Adagrad,48,29,1.0034672303585728,61,1.4982315301895142
Adadelta,36,30,1.0081633174779654,99,0.11689276993274689
Adadelta,41,24,1.0053198057929764,128,0.13052509725093842
SGD,33,30,1.005807896308621,92,1.3581678867340088
Adadelta,60,30,1.009805574121388,49,0.07773765921592712
Ftrl,57,30,1.0067488479393734,77,2.3026492595672607
Adamax,40,31,1.0042011160253497,119,2.013747215270996
Adadelta,42,27,1.0092255602179203,87,0.10435167700052261
Ftrl,54,25,1.004403559147945,55,2.3024590015411377
Adadelta,40,24,1.0058895194415918,101,0.11365292966365814
Adam,32,28,1.0006006829865879,111,2.347601890563965
Adamax,51,17,1.0039458646850135,49,2.33319091796875
Adagrad,60,31,1.0041987112895123,85,2.302561044692993
Adadelta,52,19,1.0032726989395033,34,0.08865353465080261
Ftrl,37,22,1.007372268459443,87,2.3026349544525146
Adadelta,53,16,1.0020109036721612,41,0.09300488978624344
Adadelta,50,22,1.0006237919174485,115,0.10280533879995346
Adadelta,46,20,1.0078709053070092,87,0.11125683784484863
Adadelta,58,23,1.0062995911813108,123,0.09358610212802887
Ftrl,39,22,1.0071459711133148,94,2.30265736579895
Adadelta,55,23,1.0050246776104348,110,0.09521013498306274
